<!DOCTYPE html>
<html>
<head>
  <title>Face Verification ‚úÖ</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.15/dist/face-api.min.js"></script>
</head>
<body>
  <h2>üñºÔ∏è Register Face</h2>
  <input id="upload" type="file" accept="image/*">
  <br><img id="preview" style="max-width:300px;border:1px solid #ccc;">
  <br><button id="enroll">Enroll Face</button>

  <h2>üìπ Verify Live</h2>
  <video id="video" width="320" height="240" autoplay muted></video>
  <br><button id="camera">Start Camera</button>
  <button id="verify">Verify</button>

  <div id="status">Loading models...</div>

  <script>
    let enrolled = null;
    let modelsLoaded = false;

    // Load ALL required models explicitly
    async function loadModels() {
      const status = document.getElementById('status');
      status.textContent = 'Loading models...';
      
      try {
        // TinyFaceDetector + landmarks + recognition (complete set)
        await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model');
        await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model');
        await faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model');
        
        modelsLoaded = true;
        status.innerHTML = '‚úÖ <b>Models Ready!</b> Upload photo.';
        console.log('All models loaded');
      } catch(e) {
        status.textContent = `‚ùå ${e.message}`;
      }
    }

    // Registration
    document.getElementById('upload').onchange = e => {
      const file = e.target.files[0];
      document.getElementById('preview').src = URL.createObjectURL(file);
    };

    document.getElementById('enroll').onclick = async () => {
      if (!modelsLoaded) return alert('Wait for models!');
      const img = document.getElementById('preview');
      if (!img.src) return alert('Upload photo!');
      
      // EXPLICIT TinyFaceDetector options
      const opts = new faceapi.TinyFaceDetectorOptions({ 
        inputSize: 224, 
        scoreThreshold: 0.3 
      });
      
      const detection = await faceapi
        .detectSingleFace(img, opts)
        .withFaceLandmarks()
        .withFaceDescriptor();
      
      if (!detection) {
        document.getElementById('status').textContent = '‚ùå No face found';
        return;
      }
      
      enrolled = Array.from(detection.descriptor);
      document.getElementById('status').innerHTML = 
        `‚úÖ Enrolled! <b>128D vector stored</b>`;
    };

    // Camera
    document.getElementById('camera').onclick = async () => {
      const video = document.getElementById('video');
      video.srcObject = await navigator.mediaDevices.getUserMedia({ 
        video: { width: 320, height: 240 } 
      });
    };

    // Verify
    document.getElementById('verify').onclick = async () => {
      if (!modelsLoaded) return alert('Models not ready!');
      if (!enrolled) return alert('Enroll first!');
      const video = document.getElementById('video');
      if (!video.videoWidth) return alert('Start camera!');
      
      const opts = new faceapi.TinyFaceDetectorOptions({ inputSize: 224 });
      
      const detection = await faceapi
        .detectSingleFace(video, opts)
        .withFaceLandmarks()
        .withFaceDescriptor();
      
      if (!detection) {
        document.getElementById('status').textContent = '‚ùå No face in camera';
        return;
      }
      
      const distance = faceapi.utils.round(
        faceapi.euclideanDistance(enrolled, Array.from(detection.descriptor))
      );
      
      const match = distance < 0.6;
      document.getElementById('status').innerHTML = 
        match 
          ? `üéâ <b>VERIFIED!</b> Distance: ${distance}`
          : `‚ùå Not match. Distance: ${distance}`;
    };

    // Start
    loadModels();
  </script>
</body>
</html>
